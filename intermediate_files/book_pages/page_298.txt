15
Against Complacency
Dilemmas involving humans at the edge of sentience have a special gravity 
that leaves no room for doubt about their deep moral seriousness. When we 
read the testimony of Kate Bainbridge or Jill Lawson, the importance of the 
issues comes across with tremendous force. With animals such as octopuses, 
that type of direct testimony is absent, and to see the seriousness of the risks 
requires a more challenging leap of imagination. But it is one I think most of 
us can achieve with eﬀort.
The situation with AI is very diﬀerent. Here the risks are all too easy to 
dismiss. The debate concerns technology we have created, and with which we 
have no long history of interaction. Moreover, if sentient AI is achieved, it will 
be achieved in systems whose recent precursors were correctly seen as mere 
tools and playthings with no moral status. The point at which this judgement 
shifs from correct to dangerously incorrect will be very hard for us to see. 
There is a real risk that we will continue to regard these systems as our tools 
and playthings long afer they become sentient.
I have come to see the issue as a serious one, and one that does deserve the 
energy of policy- makers now. One aim of this chapter is to explain why I 
think this. In short, I fear that we may create sentient AI long before we recog-
nize we have done so. It could be much easier than we tend to think. The 
second aim is to explore possible ways forward. How can we assess sentience 
candidature in such systems? And what should we do in our current state of 
profound uncertainty?
The next three chapters are, in part, an attempt to map out unsolved prob-
lems. Nonetheless, my hope is that by thinking about these problems through 
the lens of the framework developed in earlier chapters— and its core con-
cepts of sentience candidature, precaution, and proportionality— we will arrive 
at some possible ways forward.
Downloaded from https://academic.oup.com/book/57949 by guest on 29 July 2024
