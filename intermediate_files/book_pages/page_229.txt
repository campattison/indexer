0;..3,M ­1 6)3P(E, RR 
77D
To be clear, these proposals are independent of Proposal 12. One may still 
agree that my proposed responses are on the right lines even if one thinks the 
‘brainstem rule’ sets the bar in the wrong place, and vice versa.
11.8 Summary of Chapter 11
Human neural organoids are showing great promise as models of the human 
brain, models that could potentially replace a substantial amount of animal 
research. It would be hasty to dismiss the possibility they could develop sen-
tience. However, scepticism about this idea is appropriate when considering 
current organoids (at the time of writing). This is not because of their size, 
but because of their organization: current organoids lack a functioning brain-
stem or anything equivalent to one. There are nonetheless some troubling 
early warning signs, suggesting that organoid research may create forms of 
sentient being in the future.
Researchers with very diﬀerent views about the neural basis of sentience 
can unite behind the ‘brainstem rule’: if a neural organoid develops or inner-
vates a functioning brainstem that regulates arousal and leads to sleep- wake 
cycles, then it is a sentience candidate. An artiﬁcial brainstem substitute may 
also be enough. This is proposed as a suIcient condition for sentience candi-
dature. When a system is a sentience candidate, we should take the possibility 
of its sentience seriously and discuss proportionate steps to protect its wel-
fare, despite continuing uncertainty and doubt.
What steps might be proportionate? If organoid research leads to the cre-
ation of organoids that are sentience candidates, a moratorium (time- limited 
ban) or indeﬁnite ban on the creation of this particular type of organoid may 
be appropriate, but bans should avoid indiscriminate targeting of all organoid 
research. An alternative approach, consistent with existing approaches to ani-
mal research, is to require ethical review and harm- beneﬁt analysis whenever 
a neural organoid is a sentience candidate.
The Edge of Sentience: Risk and Precaution in Humans, Other Animals, and AI. Jonathan Birch, Oxford University Press. 
© Jonathan Birch 2024. DOI: 10.1093/9780191966729.003.0012
Downloaded from https://academic.oup.com/book/57949 by guest on 29 July 2024
