6)T70,8)R’9 1-22 :;R - 6;R-T;R0U6 
325
agents as sentient and still continue to treat them appallingly, simply because 
social norms permit it. Humans have form in this area; I think there is no 
need to list examples. Metzinger’s concern is that humanity may soon have 
the ability to create a new suﬀering explosion and that, true to form, it will 
readily take that opportunity.
Consider an analogy with industrialized farming. If you had the op por tun-
ity to return to the 1950s and introduce a global moratorium on the creation 
of super- fast- growing breeds of chicken, and on the intensive farming of these 
chickens in large warehouses, would you do it? Suﬀering explosions, as the 
explosion metaphor implies, are di3cult to reverse once they have occurred. 
But they can be easy to prevent, if governments are able to see the risk in 
prospect, and press pause on the line of research and innovation that is creat-
ing the risk. The basic intuition is the same as that behind precautionary 
thinking in many other contexts, such as environmental regulation and pub-
lic health.
Metzinger has proposed that a global moratorium would be a proportion-
ate precaution against the risk of a new suﬀering explosion:
It is unethical to run incalculable risks of this magnitude. Therefore, until 
2050, there should be a global ban on all research that directly aims at or 
indirectly and knowingly risks the emergence of synthetic phenomenology.
At the same time, we should agree on an ethical obligation to allocate 
resources according to an open- ended, strictly rational, and evidence- based 
process of risk assessment, focusing on the problem of artiﬁcial suﬀering [. . .].3
What exactly is the intended scope of the moratorium? How much AI 
research ‘indirectly and knowingly risks the emergence of synthetic phenom-
enology’? The ‘and knowingly’ is a signiﬁcant qualiﬁcation, because presum-
ably the vast majority of AI research is not knowingly taking any such risk. 
Knowledge requires belief, and I suspect the vast majority of AI researchers 
do not believe they are in any way risking the creation of artiﬁcial sentience. 
But it is also unclear what justiﬁes the ‘knowingly’ requirement. In other cir-
cumstances, one does not need to know one is running a risk to be acting 
recklessly and negligently. Think of the drunk- driver who believes he is driv-
ing perfectly safely.
The di3culty for Metzinger is that our deep ignorance of the nature of 
sentience— ignorance he rightly emphasizes— leaves us unable to specify 
3 Metzinger (2021, p. 46).
Downloaded from https://academic.oup.com/book/57949 by guest on 29 July 2024
