33H 
T() RU,--()-. /R0,10/2)
with clear potential to create sentience candidates according to our current 
credible theories, leading to an oddly shaped net that seems very likely to 
miss out the most intelligent systems. All I can say in response is that I think it 
is less problematic to cast a wide net when the demand is more moderate. A 
moratorium on all AI research would involve foregoing signiﬁcant beneﬁts, 
but it is less clear that anything of value is foregone by the whole industry 
signing up to an enforceable code of practice.
Metzinger’s position is clearly that the ban must come ﬁrst; then we should 
work out the details of codes of practice and their scope. I accept this is a dif-
ﬁcult judgement call, and an issue where inclusive debate is needed. I lean 
towards the views that the potential beneﬁts of work in this area are signiﬁ-
cant and that deterring innovation would risk foregoing those beneﬁts. If one 
shares these views, the case for developing codes of good practice as we go 
along, while the research continues, becomes stronger.
Proposal 26. Codes of good practice and licensing (II). There should be a 
licensing scheme for companies attempting to create artiﬁcial sentience 
candidates, or whose work creates even a small risk of doing so, even if this 
is not an explicit aim. Obtaining a license should be dependent on signing 
up to (and, where necessary, funding the creation of ) a code of good 
practice for this type of work that includes norms of transparency.
17.4 A Call for Democratic Debate
I see both Metzinger and Schneider as doing exactly the right thing by putt-
ing proposals on the table. We need to be discussing these issues now, before 
the technology forces our hand, and people need to be making clear, concrete 
proposals to facilitate that discussion. Proposal 26 should be read as another 
proposal on the table, not necessarily the correct course for humanity to take.
It is fair to say Schneider, Metzinger and myself all subscribe to ‘the precau-
tionary principle’ in some sense,I but all this shows is that the phrase ‘precau-
tionary principle’ by itself is too vague to tell us what to do when faced with 
problems at the edge of sentience— a recurring theme of the whole book. 
Many grades of precautionary action, ranging from light- touch to drastic, can 
I Schwitzgebel and Garza (2020) have also urged taking a precautionary stance towards possibly 
sentient AI.
Downloaded from https://academic.oup.com/book/57949 by guest on 29 July 2024
